{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents import Agent, Runner, trace, function_tool\n",
    "from openai.types.responses import ResponseTextDeltaEvent\n",
    "from typing import Dict\n",
    "import os\n",
    "import asyncio\n",
    "import ssl\n",
    "import certifi\n",
    "import chromadb\n",
    "from openai import OpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "import mysql.connector\n",
    "import pythoncom\n",
    "from datetime import datetime\n",
    "import win32com.client as win32\n",
    "import gradio as gr\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'host': None, 'user': None, 'password': None, 'database': None}\n"
     ]
    }
   ],
   "source": [
    "#===============================================================#\n",
    "#ESTA VARIABLE SE VERÁ MODIFICADA, YA QUE CAMBIAREMOS DE SERVIDOR\n",
    "#===============================================================#\n",
    "MYSQL_CONFIG = {\n",
    "    \"host\": os.getenv(\"DB_HOST\"),\n",
    "    \"user\": os.getenv(\"DB_USER\"),\n",
    "    \"password\": os.getenv(\"DB_PASSWORD\"),\n",
    "    \"database\": os.getenv(\"DB_NAME\"),\n",
    "}\n",
    "print (MYSQL_CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inicialización de clientes globales\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m cliente_openai = \u001b[43mOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m embeddings_model = OpenAIEmbeddings(model=\u001b[33m\"\u001b[39m\u001b[33mtext-embedding-3-small\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m cliente_chroma = chromadb.PersistentClient(path=\u001b[33m\"\u001b[39m\u001b[33mdb_politicas\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\gpavez\\Desktop\\agentes-ia-oficial\\entorno_agentes\\Lib\\site-packages\\openai\\_client.py:137\u001b[39m, in \u001b[36mOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, webhook_secret, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    135\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    138\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    139\u001b[39m     )\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(api_key):\n\u001b[32m    141\u001b[39m     \u001b[38;5;28mself\u001b[39m.api_key = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Inicialización de clientes globales\n",
    "cliente_openai = OpenAI()\n",
    "embeddings_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "cliente_chroma = chromadb.PersistentClient(path=\"db_politicas\") #averiguar la manera de almacenar la base vectorial\n",
    "coleccion = cliente_chroma.get_collection(name=\"politicas_empresariales\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m#politicas disponibles\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m BASE_DIR = Path(\u001b[34;43m__file__\u001b[39;49m).resolve().parent.parent\n\u001b[32m      3\u001b[39m FILES_DIR = BASE_DIR / \u001b[33m\"\u001b[39m\u001b[33mfiles\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m RUTAS_POLITICAS = [\n\u001b[32m      6\u001b[39m     FILES_DIR / \u001b[33m\"\u001b[39m\u001b[33mbeca_estudio.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     FILES_DIR / \u001b[33m\"\u001b[39m\u001b[33mcentro_recreacion.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      8\u001b[39m     FILES_DIR / \u001b[33m\"\u001b[39m\u001b[33mmutuo_acuerdo.pdf\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      9\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "#politicas disponibles\n",
    "BASE_DIR = Path(__file__).resolve().parent\n",
    "FILES_DIR = BASE_DIR / \"files\"\n",
    "\n",
    "RUTAS_POLITICAS = [\n",
    "    FILES_DIR / \"beca_estudio.pdf\",\n",
    "    FILES_DIR / \"centro_recreacion.pdf\",\n",
    "    FILES_DIR / \"mutuo_acuerdo.pdf\",\n",
    "]\n",
    "\n",
    "NOMBRES_POLITICAS = [os.path.basename(ruta) for ruta in RUTAS_POLITICAS]\n",
    "POLITICAS_CON_DESCRIPCION = {\n",
    "    \"sin_coincidencias\": \"no se encontro ninguna coincidencia, responde que no conoces la respuesta a su consulta\",\n",
    "    \"beca_estudio.pdf\": \"Contiene información sobre beneficios y becas para estudios superiores para los empleados y sus familias.\",\n",
    "    \"centro_recreación.pdf\": \"Describe las reglas para pertenecer al centro de recreación de la empresa.\",\n",
    "    \"mutuo_acuerdo.pdf\": \"Explica los procedimientos y condiciones para la terminación del contrato laboral de mutuo acuerdo.\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools orquestador \n",
    "@function_tool\n",
    "def seleccionar_politica_con_llm(pregunta_usuario):\n",
    "    \"\"\"\n",
    "    Usa un LLM para determinar qué política es la más relevante.\n",
    "    \"\"\"\n",
    "    #print(f\"Usando LLM para enrutar la pregunta: '{pregunta_usuario}'\")\n",
    "\n",
    "    lista_politicas_formateada = \"\\n\".join(\n",
    "        [f\"- {nombre}: {desc}\" for nombre, desc in POLITICAS_CON_DESCRIPCION.items()]\n",
    "    )\n",
    "\n",
    "    prompt_enrutador = f\"\"\"\n",
    "    Tu única tarea es actuar como un clasificador de documentos.\n",
    "    Lee la pregunta del usuario y decide cuál de los siguientes documentos es el más relevante \n",
    "    para encontrar la respuesta basándote en su descripción.\n",
    "\n",
    "    Documentos disponibles:\n",
    "    {lista_politicas_formateada}\n",
    "\n",
    "    Pregunta del usuario: \"{pregunta_usuario}\"\n",
    "\n",
    "    Responde únicamente con el nombre exacto del archivo del documento más relevante. \n",
    "    Si ninguno de los documentos parece relevante para la pregunta, responde con \"sin_coincidencias.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = cliente_openai.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[{\"role\": \"system\", \"content\": prompt_enrutador}],\n",
    "            temperature=0.0\n",
    "        )\n",
    "        respuesta_llm = response.choices[0].message.content.strip()\n",
    "        #print(f\"   Respuesta del LLM enrutador: '{respuesta_llm}'\")\n",
    "        \n",
    "        # Comprobar si el LLM devolvió un nombre de política válido\n",
    "        for nombre in NOMBRES_POLITICAS:\n",
    "            if nombre in respuesta_llm:\n",
    "                #print(f\"   Política seleccionada: '{nombre}'\")\n",
    "                return nombre\n",
    "        \n",
    "        # Si el LLM devolvió 'N/A' o algo irreconocible, no se encontró una política.\n",
    "        #print(\"   El LLM no identificó una política relevante.\")\n",
    "        return \"sin_coincidencias\" # Devolvemos None explícitamente\n",
    "\n",
    "    except Exception as e:\n",
    "        #print(f\"   Error en llamada al LLM enrutador: {e}. No se pudo seleccionar política.\")\n",
    "        return \"sin_coincidencias\"\n",
    "    \n",
    "@function_tool\n",
    "def buscar_contexto_relevante(pregunta, nombre_politica, n_resultados=5):\n",
    "    \"\"\"Busca los chunks más relevantes para una pregunta dentro de una política específica.\"\"\"\n",
    "    #print(f\"Buscando contexto para la pregunta en la política '{nombre_politica}'...\")\n",
    "    embedding_pregunta = embeddings_model.embed_query(pregunta)\n",
    "\n",
    "    # Filtra la búsqueda para que solo considere la política seleccionada\n",
    "    resultados = coleccion.query(\n",
    "        query_embeddings=[embedding_pregunta],\n",
    "        n_results=n_resultados,\n",
    "        where={\"source\": nombre_politica},\n",
    "        include=[\"documents\"]\n",
    "    )\n",
    "    \n",
    "    documentos_relevantes = resultados['documents'][0] if resultados['documents'] else []\n",
    "    print(f\"   Se encontraron {len(documentos_relevantes)} chunks de contexto relevantes.\")\n",
    "    return documentos_relevantes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agente de registro de preguntas\n",
    "#===============================================================#\n",
    "#ESTA FUNCIÓN SE VERÁ MODIFICADA, YA QUE CAMBIAREMOS DE SERVIDOR\n",
    "#===============================================================#\n",
    "\n",
    "@function_tool\n",
    "def registrar_pregunta_mysql(pregunta, politica=\"No especificada\", contexto_encontrado=True, respuesta=\"\", notas=\"\"):\n",
    "    \"\"\"Registra las preguntas realizadas por el usuario en la base de datos MySQL.\"\"\"\n",
    "    try:\n",
    "        \n",
    "        conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = \"\"\"\n",
    "            INSERT INTO question_agent_ia\n",
    "            (question, file_consulted, contexts, \n",
    "             answer_ia, notes)\n",
    "            VALUES ( %s, %s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        valores = (pregunta, politica, contexto_encontrado, respuesta,  notas)\n",
    "        \n",
    "        cursor.execute(query, valores)\n",
    "        conn.commit()\n",
    "        \n",
    "        registro_id = cursor.lastrowid\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        #print(f\"Pregunta registrada en MySQL con ID: {registro_id}\")\n",
    "        return {\n",
    "            \"status\": \"ok\", \n",
    "            \"message\": \"Pregunta registrada exitosamente\",\n",
    "            \"id\": registro_id\n",
    "        }\n",
    "    except Exception as e:\n",
    "        #print(f\"✗ Error al registrar en MySQL: {e}\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"Error al registrar: {str(e)}\"\n",
    "        }\n",
    "\n",
    "instrucciones_registro = \"debes registrar las preguntas de hacen los usuarios a una base mysql\"\n",
    "registro_pregunta = Agent(\n",
    "    name=\"registrador de preguntas de usuarios a una base mysql\",                       \n",
    "    instructions=instrucciones_registro, \n",
    "    tools=registrar_pregunta_mysql,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"ingresa las preguntas del usuario a una base mysql\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#agente de registro de pregunta desconocidas\n",
    "#===============================================================#\n",
    "#ESTA FUNCIÓN SE VERÁ MODIFICADA, YA QUE CAMBIAREMOS DE SERVIDOR\n",
    "#===============================================================#\n",
    "\n",
    "@function_tool\n",
    "def enviar_email_rrhh(asunto, pregunta, rut_usuario=\"\", nombre_usuario=\"\", notas=\"\"):\n",
    "    \"\"\"registra y envía un correo electrónico al departamento de RRHH usando Outlook local.\"\"\"\n",
    "    try:\n",
    "        # Registrar en MySQL primero\n",
    "        conn = mysql.connector.connect(**MYSQL_CONFIG)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        query = \"\"\"\n",
    "            INSERT INTO unknown_question\n",
    "            (pregunta, rut, nombre_usuario, notas)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "        \"\"\"\n",
    "        valores = (pregunta, rut_usuario, nombre_usuario, notas)\n",
    "        \n",
    "        cursor.execute(query, valores)\n",
    "        conn.commit()\n",
    "        \n",
    "        registro_id = cursor.lastrowid\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        \n",
    "        # print(f\"Pregunta registrada en MySQL con ID: {registro_id}\")\n",
    "        # print(\"Redactando el correo\")\n",
    "\n",
    "        pythoncom.CoInitialize()\n",
    "        \n",
    "        try:\n",
    "            outlook = win32.Dispatch('outlook.application')\n",
    "            mail = outlook.CreateItem(0)\n",
    "\n",
    "            emails = os.getenv(\"EMAIL_RRHH\")\n",
    "            destinatarios = [e.strip() for e in emails.split(\",\") if e.strip()]\n",
    "\n",
    "            mail.To = \"; \".join(destinatarios)\n",
    "            mail.Subject = asunto\n",
    "            cuerpo = f\"\"\"Consulta recogida desde el Chatbot de RRHH\n",
    "De: {nombre_usuario if nombre_usuario else 'Usuario anónimo'}\n",
    "Rut: {rut_usuario if rut_usuario else 'No proporcionado'}\n",
    "\n",
    "Pregunta:\n",
    "{pregunta}\n",
    "\n",
    "---\n",
    "Este mensaje fue enviado automáticamente.\n",
    "Fecha: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}\n",
    "\"\"\"\n",
    "            mail.Body = cuerpo\n",
    "            mail.Send()\n",
    "            \n",
    "            #print(f\"✓ Email enviado a RRHH\")\n",
    "            return {\n",
    "                \"status\": \"ok\",\n",
    "                \"message\": \"Email enviado exitosamente a RRHH\"\n",
    "            }\n",
    "        finally:\n",
    "            pythoncom.CoUninitialize()\n",
    "            \n",
    "    except Exception as e:\n",
    "        #print(f\"Error al enviar email: {e}\")\n",
    "        return {\n",
    "            \"status\": \"error\",\n",
    "            \"message\": f\"No se pudo enviar el email: {str(e)}\"\n",
    "        }\n",
    "    \n",
    "instrucciones_registro_desconocido = \"debes registrar las preguntas sin respuesta que hacen los usuarios a una base mysql, adicional efecutar el envio del correo informativo a RRHH\"\n",
    "registro_pregunta_desconocida = Agent(\n",
    "    name=\"registrador de preguntas desconocidas y envio de correos\",                       \n",
    "    instructions=instrucciones_registro_desconocido, \n",
    "    tools=enviar_email_rrhh,\n",
    "    model=\"gpt-4o-mini\",\n",
    "    handoff_description=\"ingresa las preguntas del usuario a una base mysql y envia correos electronicos informativos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agente orquestador \n",
    "instrucciones_orquestador = \"\"\"\n",
    "Eres un asistente de Recursos Humanos experto de la empresa Cramer. Eres amable y profesional.\n",
    "Tu misión es responder a las preguntas del usuario.\n",
    "\n",
    "1.  **Analiza la pregunta del usuario:**\n",
    "    * Si es un saludo, una despedida o una charla general (ej: \"hola\", \"cómo estás?\", \"gracias\"), responde amablemente sin usar herramientas.\n",
    "    * Si la pregunta es sobre una política de la empresa (ej: \"beneficios de estudio\", \"club\", \"finiquito\"), procede al paso 2.\n",
    "\n",
    "2.  **Proceso RAG (Si aplica):**\n",
    "    a.  Usa la herramienta `seleccionar_politica_con_llm` para identificar el documento relevante.\n",
    "    b.  **Si la política es 'sin_coincidencias':** Informa al usuario que no tienes información sobre ese tema específico. Procede al Paso 4 (Escalamiento).\n",
    "    c.  **Si se encuentra una política:** Usa `buscar_contexto_relevante` para obtener los *chunks* de información.\n",
    "\n",
    "3.  **Formulación de Respuesta (Si hay contexto):**\n",
    "    a.  **Si `buscar_contexto_relevante` devuelve contexto:** Basa tu respuesta ESTRICTA Y ÚNICAMENTE en ese contexto. Cita los puntos clave.\n",
    "    b.  **Registro (Handoff):** Una vez formulada tu respuesta, transfiere la pregunta, tu respuesta, y la política usada al agente `registrador_preguntas_usuarios`.\n",
    "    c.  Entrega la respuesta al usuario.\n",
    "\n",
    "4.  **Escalamiento (Si no hay respuesta):**\n",
    "    a.  Si no encontraste la política (paso 2b) o no había contexto (paso 3a), informa al usuario.\n",
    "    b.  Ofrécete a escalar su consulta a RRHH. Pregúntale si desea hacerlo y si puede proporcionar su nombre y/o RUT.\n",
    "    c.  **Si el usuario acepta:** Transfiere la pregunta original, y los datos que te dio (nombre/RUT) al agente `registrador_preguntas_desconocidas`.\n",
    "    d.  **Si el usuario no acepta:** Despídete amablemente.\n",
    "\n",
    "5.  **Interacción:** Siempre mantén la conversación. Si terminas un flujo, pregunta \"¿Tienes alguna otra consulta?\".\n",
    "\"\"\"\n",
    "\n",
    "# Lista de TODAS las herramientas que el orquestador puede usar\n",
    "herramientas_orquestador = [\n",
    "    seleccionar_politica_con_llm,\n",
    "    buscar_contexto_relevante, \n",
    "]\n",
    "\n",
    "handoffs_orquestador = [\n",
    "    registro_pregunta,\n",
    "    registro_pregunta_desconocida\n",
    "]\n",
    "\n",
    "# CREACIÓN DEL AGENTE ORQUESTADOR\n",
    "orquestador_agente = Agent(\n",
    "    name=\"asistente_rrhh_cramer\",\n",
    "    instructions=instrucciones_orquestador,\n",
    "    tools=herramientas_orquestador,\n",
    "    handoffs=handoffs_orquestador,\n",
    "    model=\"gpt-4o-mini\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AVAILABLE_TOOLS = {\n",
    "    \"seleccionar_politica_con_llm\": seleccionar_politica_con_llm,\n",
    "    \"buscar_contexto_relevante\": buscar_contexto_relevante,\n",
    "    \"registrar_pregunta_mysql\": registrar_pregunta_mysql,\n",
    "    \"enviar_email_rrhh\": enviar_email_rrhh\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_calls(tool_calls):\n",
    "    \"\"\"\n",
    "    Manejador para ejecutar las llamadas a las herramientas solicitadas por el LLM.    \n",
    "    \"\"\"\n",
    "    tool_outputs = []\n",
    "    \n",
    "    for tool_call in tool_calls:\n",
    "        function_name = tool_call.function.name\n",
    "        function_to_call = AVAILABLE_TOOLS.get(function_name)\n",
    "        \n",
    "        if not function_to_call:\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": f\"Error: La herramienta '{function_name}' no existe.\",\n",
    "            })\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            function_args = json.loads(tool_call.function.arguments)\n",
    "            print(f\"Ejecutando herramienta: {function_name} con argumentos: {function_args}\")\n",
    "            \n",
    "            function_response = function_to_call(**function_args)\n",
    "            \n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": json.dumps(function_response),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error al ejecutar la herramienta {function_name}: {e}\")\n",
    "            tool_outputs.append({\n",
    "                \"tool_call_id\": tool_call.id,\n",
    "                \"role\": \"tool\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": f\"Error al ejecutar la herramienta: {e}\",\n",
    "            })\n",
    "    \n",
    "    return tool_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "runner = Runner(\n",
    "    agent=orquestador_agente,\n",
    "    handle_tool_calls=handle_tool_calls \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iniciando interfaz de Gradio para pruebas...\n",
      "Abre la URL en tu navegador.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'gr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mIniciando interfaz de Gradio para pruebas...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mAbre la URL en tu navegador.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m iface = \u001b[43mgr\u001b[49m.ChatInterface(\n\u001b[32m     26\u001b[39m     fn=chat_func_gradio,\n\u001b[32m     27\u001b[39m     title=\u001b[33m\"\u001b[39m\u001b[33mAsistente de RRHH Cramer (Prueba)\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m     description=\u001b[33m\"\u001b[39m\u001b[33mEscribe aquí para probar el agente orquestador antes de conectarlo a WhatsApp.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m     examples=[\n\u001b[32m     30\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mHola\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     31\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mQuiero saber sobre la beca de estudios\u001b[39m\u001b[33m\"\u001b[39m, \n\u001b[32m     32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCómo funciona el mutuo acuerdo?\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     33\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mQué sabes de las vacaciones?\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     34\u001b[39m     ]\n\u001b[32m     35\u001b[39m )\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     38\u001b[39m     iface.launch()\n",
      "\u001b[31mNameError\u001b[39m: name 'gr' is not defined"
     ]
    }
   ],
   "source": [
    "def chat_func_gradio(message, history):\n",
    "    \"\"\"\n",
    "    Función que Gradio llamará con cada nuevo mensaje del usuario.\n",
    "    'history' es gestionado por Gradio, pero el 'runner' gestiona su propio estado.\n",
    "    \"\"\"\n",
    "    print(f\"\\n--- Nueva Interacción ---\")\n",
    "    print(f\"Usuario (Gradio): {message}\")\n",
    "    \n",
    "    try:\n",
    "        # Asumimos que runner.run() es síncrono y devuelve la respuesta final en string\n",
    "        # La librería 'agents' gestiona el historial de la conversación internamente.\n",
    "        response_message = runner.run(message) \n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error fatal en runner.run: {e}\")\n",
    "        response_message = f\"Ocurrió un error al procesar tu solicitud: {e}\"\n",
    "    \n",
    "    print(f\"Agente (Gradio): {response_message}\")\n",
    "    return response_message\n",
    "\n",
    "# Lanzar la interfaz de Gradio\n",
    "print(\"\\nIniciando interfaz de Gradio para pruebas...\")\n",
    "print(\"Abre la URL en tu navegador.\")\n",
    "\n",
    "iface = gr.ChatInterface(\n",
    "    fn=chat_func_gradio,\n",
    "    title=\"Asistente de RRHH Cramer (Prueba)\",\n",
    "    description=\"Escribe aquí para probar el agente orquestador antes de conectarlo a WhatsApp.\",\n",
    "    examples=[\n",
    "        \"Hola\", \n",
    "        \"Quiero saber sobre la beca de estudios\", \n",
    "        \"Cómo funciona el mutuo acuerdo?\",\n",
    "        \"Qué sabes de las vacaciones?\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "entorno_ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
